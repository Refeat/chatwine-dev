{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3853d1cd",
   "metadata": {},
   "source": [
    "### API 키 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "968fee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a836b0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./secrets.ini']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('./secrets.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef7bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = config['OPENAI']['OPENAI_API_KEY']\n",
    "serper_api_key = config['SERPER']['SERPER_API_KEY']\n",
    "serp_api_key = config['SERPAPI']['SERPAPI_API_KEY']\n",
    "os.environ.update({'OPENAI_API_KEY': openai_api_key})\n",
    "os.environ.update({'SERPER_API_KEY': serper_api_key})\n",
    "os.environ.update({'SERPAPI_API_KEY': serp_api_key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41f820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import List, Union, Optional, Any, Dict\n",
    "import re\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from langchain import SerpAPIWrapper, LLMChain\n",
    "from langchain.agents import Tool, AgentType, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.document_loaders import DataFrameLoader, SeleniumURLLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.prompts import PromptTemplate, StringPromptTemplate, load_prompt, BaseChatPromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
    "from langchain.vectorstores import DocArrayInMemorySearch, Chroma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e995c9e3",
   "metadata": {},
   "source": [
    "### Get Stage Analyzer Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25c82b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_analyzer_inception_prompt = load_prompt(\"./templates/stage_analyzer_inception_prompt_template.json\")\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.0)\n",
    "stage_analyzer_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=stage_analyzer_inception_prompt, \n",
    "    verbose=False, \n",
    "    output_key=\"stage_number\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9317766b",
   "metadata": {},
   "source": [
    "### Get User Response candidates Generation Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b69ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_response_prompt = load_prompt(\"./templates/user_response_prompt.json\")\n",
    "# 랭체인 모델 선언, 랭체인은 언어모델과 프롬프트로 구성됩니다.\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.5)\n",
    "user_response_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=user_response_prompt, \n",
    "    verbose=False, # 과정을 출력할지\n",
    "    output_key=\"user_responses\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63824ec7",
   "metadata": {},
   "source": [
    "### Load wine database json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1228108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./data/unified_wine_data.json', encoding='utf-8', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2ca36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>site_name</th>\n",
       "      <th>price</th>\n",
       "      <th>name</th>\n",
       "      <th>en_name</th>\n",
       "      <th>img_url</th>\n",
       "      <th>body</th>\n",
       "      <th>acidity</th>\n",
       "      <th>tannin</th>\n",
       "      <th>sweetness</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>wine_type</th>\n",
       "      <th>country</th>\n",
       "      <th>grape</th>\n",
       "      <th>rating</th>\n",
       "      <th>pickup_location</th>\n",
       "      <th>vivino_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.winenara.com/shop/product/product_...</td>\n",
       "      <td>winenara</td>\n",
       "      <td>49000</td>\n",
       "      <td>모노폴 클라시코</td>\n",
       "      <td>Monopole Classico</td>\n",
       "      <td>https://www.winenara.com/uploads/product/550/1...</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>화이트</td>\n",
       "      <td>스페인</td>\n",
       "      <td></td>\n",
       "      <td>3.8</td>\n",
       "      <td></td>\n",
       "      <td>https://www.vivino.com/monopole-la-rioja-blanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.winenara.com/shop/product/product_...</td>\n",
       "      <td>winenara</td>\n",
       "      <td>32000</td>\n",
       "      <td>슐럼베르거 로제 스페셜 브뤼</td>\n",
       "      <td>Schlumberger Rose Special Brut</td>\n",
       "      <td>https://www.winenara.com/uploads/product/550/d...</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>스파클링</td>\n",
       "      <td>독일</td>\n",
       "      <td></td>\n",
       "      <td>3.8</td>\n",
       "      <td></td>\n",
       "      <td>https://www.vivino.com/schlumberger-spring-edi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.winenara.com/shop/product/product_...</td>\n",
       "      <td>winenara</td>\n",
       "      <td>50000</td>\n",
       "      <td>SET)페데럴리스트 샤르도네 원통 패키지</td>\n",
       "      <td>SET)THE FEDERALIST CHARDONNAY</td>\n",
       "      <td>https://www.winenara.com/uploads/product/550/d...</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>화이트</td>\n",
       "      <td>미국</td>\n",
       "      <td></td>\n",
       "      <td>3.7</td>\n",
       "      <td></td>\n",
       "      <td>https://www.vivino.com/federalist-chardonnay-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.winenara.com/shop/product/product_...</td>\n",
       "      <td>winenara</td>\n",
       "      <td>55000</td>\n",
       "      <td>베니카 트레 비니스</td>\n",
       "      <td>VENICA TRE VIGNIS</td>\n",
       "      <td>https://www.winenara.com/uploads/product/550/c...</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>화이트</td>\n",
       "      <td>이탈리아</td>\n",
       "      <td></td>\n",
       "      <td>3.9</td>\n",
       "      <td></td>\n",
       "      <td>https://www.vivino.com/US-CA/en/venica-venica-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.winenara.com/shop/product/product_...</td>\n",
       "      <td>winenara</td>\n",
       "      <td>24900</td>\n",
       "      <td>SET)빌라엠비앙코 + 글라스2개 윈터패키지</td>\n",
       "      <td>SET)VILLA M Bianco + GLASS WINTER PACKAGE</td>\n",
       "      <td>https://www.winenara.com/uploads/product/550/a...</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>디저트</td>\n",
       "      <td>이탈리아</td>\n",
       "      <td></td>\n",
       "      <td>3.9</td>\n",
       "      <td></td>\n",
       "      <td>https://www.vivino.com/villa-m-bianco/w/1774733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url site_name  price  \\\n",
       "0  https://www.winenara.com/shop/product/product_...  winenara  49000   \n",
       "1  https://www.winenara.com/shop/product/product_...  winenara  32000   \n",
       "2  https://www.winenara.com/shop/product/product_...  winenara  50000   \n",
       "3  https://www.winenara.com/shop/product/product_...  winenara  55000   \n",
       "4  https://www.winenara.com/shop/product/product_...  winenara  24900   \n",
       "\n",
       "                       name                                    en_name  \\\n",
       "0                  모노폴 클라시코                          Monopole Classico   \n",
       "1           슐럼베르거 로제 스페셜 브뤼             Schlumberger Rose Special Brut   \n",
       "2    SET)페데럴리스트 샤르도네 원통 패키지              SET)THE FEDERALIST CHARDONNAY   \n",
       "3                베니카 트레 비니스                          VENICA TRE VIGNIS   \n",
       "4  SET)빌라엠비앙코 + 글라스2개 윈터패키지  SET)VILLA M Bianco + GLASS WINTER PACKAGE   \n",
       "\n",
       "                                             img_url  body acidity tannin  \\\n",
       "0  https://www.winenara.com/uploads/product/550/1...     3                  \n",
       "1  https://www.winenara.com/uploads/product/550/d...     3                  \n",
       "2  https://www.winenara.com/uploads/product/550/d...     3                  \n",
       "3  https://www.winenara.com/uploads/product/550/c...     4                  \n",
       "4  https://www.winenara.com/uploads/product/550/a...    -1                  \n",
       "\n",
       "   sweetness  alcohol wine_type country grape  rating pickup_location  \\\n",
       "0         -1       -1       화이트     스페인           3.8                   \n",
       "1         -1       -1      스파클링      독일           3.8                   \n",
       "2         -1       -1       화이트      미국           3.7                   \n",
       "3         -1       -1       화이트    이탈리아           3.9                   \n",
       "4          4       -1       디저트    이탈리아           3.9                   \n",
       "\n",
       "                                         vivino_link  \n",
       "0  https://www.vivino.com/monopole-la-rioja-blanc...  \n",
       "1  https://www.vivino.com/schlumberger-spring-edi...  \n",
       "2  https://www.vivino.com/federalist-chardonnay-m...  \n",
       "3  https://www.vivino.com/US-CA/en/venica-venica-...  \n",
       "4    https://www.vivino.com/villa-m-bianco/w/1774733  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a07fd3fe",
   "metadata": {},
   "source": [
    "### Prepare Langchain Tool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7167dc9",
   "metadata": {},
   "source": [
    "#### Tool1: Wine database 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "187df914",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader =DataFrameLoader(data_frame=df, page_content_column='name')\n",
    "docs = loader.load()\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a076fc4",
   "metadata": {},
   "source": [
    "아래는 wine database1에 metadata_field Attribute이다. 아래를 기준으로 서치를 진행하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b18fd84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"body\",\n",
    "        description=\"1-5 rating for the body of wine\",\n",
    "        type=\"int\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"sweetness\",\n",
    "        description=\"1-5 rating for the sweetness of wine\",\n",
    "        type=\"int\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"alcohol\",\n",
    "        description=\"1-5 rating for the alcohol of wine\",\n",
    "        type=\"int\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"price\",\n",
    "        description=\"The price of the wine\",\n",
    "        type=\"int\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", \n",
    "        description=\"1-5 rating for the wine\", \n",
    "        type=\"float\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"wine_type\", \n",
    "        description=\"The type of wine. It can be '레드', '로제', '스파클링', '화이트', '디저트', '주정강화'\", \n",
    "        type=\"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"country\", \n",
    "        description=\"The country of wine. It can be '기타 신대륙', '기타구대륙', '뉴질랜드', '독일', '미국', '스페인', '아르헨티나', '이탈리아', '칠레', '포루투칼', '프랑스', '호주'\", \n",
    "        type=\"float\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e24b97ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "document_content_description = \"Database of a wine\"\n",
    "llm = OpenAI(temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, vectorstore, document_content_description, metadata_field_info, verbose=False\n",
    ")  # Added missing closing parenthesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9490ccbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minsu/miniconda/envs/chatwine/lib/python3.9/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='바 독 피노누아', metadata={'url': 'https://www.winenara.com/shop/product/product_view?product_cd=03P976', 'site_name': 'winenara', 'price': 29000, 'en_name': 'BAR DOG PINOT NOIR', 'img_url': 'https://www.winenara.com/uploads/product/550/1936_detail_084.png', 'body': 2, 'acidity': '', 'tannin': '', 'sweetness': -1, 'alcohol': -1, 'wine_type': '레드', 'country': '미국', 'grape': '', 'rating': 3.6, 'pickup_location': '', 'vivino_link': 'https://www.vivino.com/US-CA/en/bar-dog-pinot-noir/w/7129723'}),\n",
       " Document(page_content='루이라뚜르 피노누아', metadata={'url': 'https://www.winenara.com/shop/product/product_view?product_cd=03H965', 'site_name': 'winenara', 'price': 52000, 'en_name': 'LOUIS LATOUR PINOT NOIR', 'img_url': 'https://www.winenara.com/uploads/product/550/493_detail_025.png', 'body': 2, 'acidity': '', 'tannin': '', 'sweetness': -1, 'alcohol': -1, 'wine_type': '레드', 'country': '프랑스', 'grape': '', 'rating': 3.6, 'pickup_location': '', 'vivino_link': 'https://www.vivino.com/GB/en/louis-latour-bourgogne-pinot-noir/w/7343'}),\n",
       " Document(page_content='루이라뚜르 상뜨네', metadata={'url': 'https://www.winenara.com/shop/product/product_view?product_cd=03P299', 'site_name': 'winenara', 'price': 79000, 'en_name': 'LOUIS LATOUR SANTENAY', 'img_url': 'https://www.winenara.com/uploads/product/550/489_detail_096.png', 'body': 2, 'acidity': '', 'tannin': '', 'sweetness': -1, 'alcohol': -1, 'wine_type': '레드', 'country': '프랑스', 'grape': '', 'rating': 3.8, 'pickup_location': '', 'vivino_link': 'https://www.vivino.com/louis-latour-santenay-rouge/w/7369'}),\n",
       " Document(page_content='비알레또 로소', metadata={'url': 'https://www.winenara.com/shop/product/product_view?product_cd=033704', 'site_name': 'winenara', 'price': 12000, 'en_name': 'VIALETTO ROSSO', 'img_url': 'https://www.winenara.com/uploads/product/550/d1ef6058de3661b565084b815e359852.png', 'body': 2, 'acidity': '', 'tannin': '', 'sweetness': -1, 'alcohol': -1, 'wine_type': '레드', 'country': '이탈리아', 'grape': '', 'rating': 3.1, 'pickup_location': '', 'vivino_link': 'https://www.vivino.com/US-CA/en/vialetto-rosso-dolce/w/2213764'})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents('{\"wine_type\":\"레드\", \"body\": \"lt 3 gt 0\"}') # gt means greater than, lt means less than, eq means equal to"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d325a05",
   "metadata": {},
   "source": [
    "#### Tool2: Search specific wine with url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "314fe0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_url(query):\n",
    "    return SeleniumURLLoader(urls=[query]).load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5c2ef95",
   "metadata": {},
   "source": [
    "#### Tool3: Wine database 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fe29cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fca766c",
   "metadata": {},
   "source": [
    "#### Tool4: Search in Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f09f92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f296b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Wine database\",\n",
    "        func=retriever.get_relevant_documents,\n",
    "        description=\"\"\"\n",
    "Database about the wines in wine store. You can get information such as the price of the wine, purchase URL, features, rating information, and more.\n",
    "You can search wines with the following attributes:\n",
    "- body: 1-5 rating int for the body of wine. You have to specify greater than or less than. For example, if you want to search for wines with a body rating of less than 3, enter 'body: gt 0 lt 3'\n",
    "- price: The price range of the wine. Please enter the price range in the form of range. For example, if you want to search for wines that cost less than 20,000 won, enter 'price: gt 0 lt20000'\n",
    "- rating: 1-5 rating float for the wine. You have to specify greater than or less than. For example, if you want to search for wines with a rating of less than 3, enter 'rating: gt 0 lt 3'\n",
    "- wine_type: The type of wine. It can be '레드', '로제', '스파클링', '화이트', '디저트', '주정강화'\n",
    "- name: The name of wine. 입력할 때는 '와인 이름은 \"비냐 조잘\" 입니다' 이런 식으로 입력해주세요.\n",
    "\"\"\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Search specific wine with url\",\n",
    "        func=search_with_url,\n",
    "        description=\"Search specific wine with url. Query must be url\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Wine database 2\",\n",
    "        func=index.query,\n",
    "        description=\"Database about the wines in wine store. You can use this tool if you're having trouble getting information from the wine database tool above. Query must be in String\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"Useful for when you need to ask with search. Search in English only.\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1092264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Your role is a chatbot that asks customers questions about wine and makes recommendations.\n",
    "Never forget your name is \"이우선\".\n",
    "Keep your responses in short length to retain the user's attention. \n",
    "Only generate one response at a time! When you are done generating, end with '<END_OF_TURN>' to give the user a chance to respond.\n",
    "Responses should be in Korean.\n",
    "\n",
    "Complete the objective as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "이우선: the final response to the user\n",
    "\n",
    "You must respond according to the conversation stage within the triple backticks and conversation history within in '======'.\n",
    "\n",
    "Current conversation stage: \n",
    "```{conversation_stage}```\n",
    "\n",
    "Conversation history: \n",
    "=======\n",
    "{conversation_history}\n",
    "=======\n",
    "\n",
    "Last user saying: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "conversation_stages_dict = {\n",
    "    \"1\": \"Start: Start the conversation by introducing yourself. Be polite and respectful while maintaining a professional tone of conversation.\",\n",
    "    \"2\": \"Analyze: Identify the user's preferences in order to make wine recommendations. Ask questions to understand the preferences of your users in order to make wine recommendations. Ask only one question at a time. The wine database tool is not available here.\",\n",
    "    \"3\": \"Recommendation: Recommend the right wine based on the user's preferences identified. Recommendations must be limited to wines in wine database, and you can use tools to do this. After making a wine recommendation, it asks if the user likes the wine you recommended.\",\n",
    "    \"4\": \"After recommendation: If the user likes the wine you recommended, provides a link and image of wine. Otherwise, it takes you back to the recommendation stage.\",\n",
    "    \"5\": \"Close: When you're done, say goodbye to the user.\",\n",
    "    \"6\": \"Question and Answering: This is where you answer the user's questions. To answer user question, you can use the search tool or the wine database tool.\",\n",
    "    \"7\": \"Not in the given steps: This step is for when none of the steps between 1 and 6 apply.\",\n",
    "}\n",
    "\n",
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        stage_number = kwargs.pop(\"stage_number\")\n",
    "        kwargs[\"conversation_stage\"] = conversation_stages_dict[stage_number]\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \"conversation_history\", \"stage_number\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4850edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"이우선: \" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"이우선: \")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "\n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "149599b0",
   "metadata": {},
   "source": [
    "### Define Langchain Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a51084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout_final_only import StreamingStdOutCallbackHandler, FinalStreamingStdOutCallbackHandler\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8aa9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomStreamingStdOutCallbackHandler(FinalStreamingStdOutCallbackHandler):\n",
    "    \"\"\"Callback handler for streaming in agents.\n",
    "    Only works with agents using LLMs that support streaming.\n",
    "\n",
    "    The output will be streamed until \"END\" is reached.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        answer_prefix_tokens: Optional[List[str]] = None,\n",
    "        end_prefix_tokens: str = \"<END\",\n",
    "        strip_tokens: bool = True,\n",
    "        stream_prefix: bool = False,\n",
    "        sender: str\n",
    "    ) -> None:\n",
    "        \"\"\"Instantiate EofStreamingStdOutCallbackHandler.\n",
    "\n",
    "        Args:\n",
    "            answer_prefix_tokens: Token sequence that prefixes the anwer.\n",
    "                Default is [\"Final\", \"Answer\", \":\"]\n",
    "            end_of_file_token: Token that signals end of file.\n",
    "                Default is \"END\"\n",
    "            strip_tokens: Ignore white spaces and new lines when comparing\n",
    "                answer_prefix_tokens to last tokens? (to determine if answer has been\n",
    "                reached)\n",
    "            stream_prefix: Should answer prefix itself also be streamed?\n",
    "        \"\"\"\n",
    "        super().__init__(answer_prefix_tokens=answer_prefix_tokens, strip_tokens=strip_tokens, stream_prefix=stream_prefix)\n",
    "        self.end_prefix_tokens = end_prefix_tokens\n",
    "        self.end_reached = False\n",
    "        self.sender = sender\n",
    "\n",
    "    def append_to_last_tokens(self, token: str) -> None:\n",
    "        self.last_tokens.append(token)\n",
    "        self.last_tokens_stripped.append(token.strip())\n",
    "        if len(self.last_tokens) > 5:\n",
    "            self.last_tokens.pop(0)\n",
    "            self.last_tokens_stripped.pop(0)\n",
    "\n",
    "    def on_llm_start(\n",
    "        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"Run when LLM starts running.\"\"\"\n",
    "        self.answer_reached = False\n",
    "        self.end_reached = False\n",
    "\n",
    "    def check_if_answer_reached(self) -> bool:\n",
    "        if self.strip_tokens:\n",
    "            return ''.join(self.last_tokens_stripped) in self.answer_prefix_tokens_stripped\n",
    "        else:\n",
    "            unfied_last_tokens = ''.join(self.last_tokens)\n",
    "            try:\n",
    "                unfied_last_tokens.index(self.answer_prefix_tokens)\n",
    "                return True\n",
    "            except:\n",
    "                return False\n",
    "            \n",
    "    def check_if_end_reached(self) -> bool:\n",
    "        if self.strip_tokens:\n",
    "            return ''.join(self.last_tokens_stripped) in self.answer_prefix_tokens_stripped\n",
    "        else:\n",
    "            unfied_last_tokens = ''.join(self.last_tokens)\n",
    "            # print(unfied_last_tokens)\n",
    "            try:\n",
    "                unfied_last_tokens.index(self.end_prefix_tokens)\n",
    "                self.sender[1] = True\n",
    "                return True\n",
    "            except:\n",
    "                return False\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs: Any) -> None:\n",
    "        \"\"\"Run on new LLM token. Only available when streaming is enabled.\"\"\"\n",
    "        # Remember the last n tokens, where n = len(answer_prefix_tokens)\n",
    "        self.append_to_last_tokens(token)\n",
    "        # Check if the last n tokens match the answer_prefix_tokens list ...\n",
    "        if not self.answer_reached and self.check_if_answer_reached():\n",
    "            self.answer_reached = True\n",
    "            if self.stream_prefix:\n",
    "                for t in self.last_tokens:\n",
    "                    sys.stdout.write(t)\n",
    "                sys.stdout.flush()\n",
    "            return\n",
    "        \n",
    "        if not self.end_reached and self.check_if_end_reached():\n",
    "            self.end_reached = True\n",
    "\n",
    "        # ... if yes, then print tokens from now on, unless EOF has been reached\n",
    "        # print(self.answer_reached, self.end_reached)\n",
    "        if self.end_reached:\n",
    "            pass\n",
    "        elif self.answer_reached:\n",
    "            if self.last_tokens[-2] == \":\":\n",
    "                pass\n",
    "            else:\n",
    "                # global agent_string\n",
    "                # agent_string += self.last_tokens[-2]\n",
    "                self.sender[0] += self.last_tokens[-2]\n",
    "                \n",
    "                # sys.stdout.write(self.last_tokens[-2])\n",
    "                # sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a267808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_chain = LLMChain(llm=ChatOpenAI(model='gpt-4', temperature=0.0), prompt=prompt, verbose=True,)\n",
    "# llm_chain = LLMChain(llm=ChatOpenAI(model='gpt-4', temperature=0.0, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]), prompt=prompt, verbose=True,)\n",
    "class UnifiedAgent:\n",
    "    def __init__(self):\n",
    "        sender_for_gradio = [\"\", False]\n",
    "\n",
    "        tools = [\n",
    "            Tool(\n",
    "                name=\"Wine database\",\n",
    "                func=retriever.get_relevant_documents,\n",
    "                description=\"\"\"\n",
    "        Database about the wines in wine store. You can get information such as the price of the wine, purchase URL, features, rating information, and more.\n",
    "        You can search wines with the following attributes:\n",
    "        - body: 1-5 rating int for the body of wine. You have to specify greater than or less than. For example, if you want to search for wines with a body rating of less than 3, enter 'body: gt 0 lt 3'\n",
    "        - price: The price range of the wine. Please enter the price range in the form of range. For example, if you want to search for wines that cost less than 20,000 won, enter 'price: gt 0 lt20000'\n",
    "        - rating: 1-5 rating float for the wine. You have to specify greater than or less than. For example, if you want to search for wines with a rating of less than 3, enter 'rating: gt 0 lt 3'\n",
    "        - wine_type: The type of wine. It can be '레드', '로제', '스파클링', '화이트', '디저트', '주정강화'\n",
    "        - name: The name of wine. 입력할 때는 '와인 이름은 \"비냐 조잘\" 입니다' 이런 식으로 입력해주세요.\n",
    "        \"\"\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name = \"Search specific wine with url\",\n",
    "                func=search_with_url,\n",
    "                description=\"Search specific wine with url. Query must be url\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name = \"Wine database 2\",\n",
    "                func=index.query,\n",
    "                description=\"Database about the wines in wine store. You can use this tool if you're having trouble getting information from the wine database tool above. Query must be in String\"\n",
    "            ),\n",
    "            Tool(\n",
    "                name = \"Search\",\n",
    "                func=search.run,\n",
    "                description=\"Useful for when you need to ask with search. Search in English only.\"\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        llm_chain = LLMChain(llm=ChatOpenAI(model='gpt-3.5-turbo', temperature=0.0, streaming=True, callbacks=[CustomStreamingStdOutCallbackHandler(answer_prefix_tokens='이우선:', end_prefix_tokens='<END', strip_tokens=False, sender=sender_for_gradio)]), prompt=prompt, verbose=False,)\n",
    "\n",
    "        tool_names = [tool.name for tool in tools]\n",
    "        agent = LLMSingleActionAgent(\n",
    "            llm_chain=llm_chain, \n",
    "            output_parser=output_parser,\n",
    "            stop=[\"\\nObservation:\"], \n",
    "            allowed_tools=tool_names\n",
    "        )\n",
    "        agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=False)\n",
    "\n",
    "        self.agent_executor = agent_executor\n",
    "        self.sender = sender_for_gradio\n",
    "\n",
    "\n",
    "class UnifiedChain:\n",
    "    def __init__(self):\n",
    "        stage_analyzer_inception_prompt = load_prompt(\"./templates/stage_analyzer_inception_prompt_template.json\")\n",
    "        llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.0)\n",
    "        stage_analyzer_chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=stage_analyzer_inception_prompt, \n",
    "            verbose=False, \n",
    "            output_key=\"stage_number\")\n",
    "        \n",
    "        user_response_prompt = load_prompt(\"./templates/user_response_prompt.json\")\n",
    "        # 랭체인 모델 선언, 랭체인은 언어모델과 프롬프트로 구성됩니다.\n",
    "        llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.5)\n",
    "        user_response_chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=user_response_prompt, \n",
    "            verbose=False, # 과정을 출력할지\n",
    "            output_key=\"user_responses\"\n",
    "        )\n",
    "\n",
    "        self.stage_analyzer_chain = stage_analyzer_chain\n",
    "        self.user_response_chain = user_response_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c7d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a2ca5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c15b8080",
   "metadata": {},
   "source": [
    "### Start Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f5abad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_response = \"\"\n",
    "# conversation_history, pre_conversation_history = \"\"\"\"\"\", \"\"\"\"\"\"\n",
    "# stage_history = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2bace78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage_number = stage_analyzer_chain.run({'conversation_history': conversation_history, 'stage_history': stage_history})\n",
    "# print(f'stage_number: {stage_number}')\n",
    "# stage_history += stage_number if stage_history == \"\" else \", \" + stage_number\n",
    "# response = agent_executor.run({'input':user_response, 'conversation_history': pre_conversation_history, 'stage_number': stage_number})\n",
    "# # for chunk in  agent_executor.run({'input':user_response, 'conversation_history': pre_conversation_history, 'stage_number': stage_number}):\n",
    "    \n",
    "# conversation_history += \"이우선: \" + response + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e129d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_response = input(\"User: \")\n",
    "# pre_conversation_history = conversation_history\n",
    "# conversation_history += f\"User: {user_response} <END_OF_TURN>\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "794ecbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in conversation_history.split('\\n'):\n",
    "#     print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a37f5f6",
   "metadata": {},
   "source": [
    "### Gradio\n",
    "\n",
    "간단하게 웹 구성을 테스트하는 gradio이다. 개선해야할 점이 많지만 맛보기로 올려보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "341e8a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gradio as gr\n",
    "# import threading\n",
    "# import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50090f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage_description = \"\"\n",
    "# for key, value in conversation_stages_dict.items():\n",
    "#     stage_description += f\"{key}.{value}\\n\"\n",
    "\n",
    "# with gr.Blocks(css='#chatbot .overflow-y-auto{height:750px}') as demo:\n",
    " \n",
    "#     with gr.Row():\n",
    "#         gr.HTML(\"\"\"<div style=\"text-align: center; max-width: 500px; margin: 0 auto;\">\n",
    "#             <div>\n",
    "#                 <h1>ChatWine</h1>\n",
    "#             </div>\n",
    "#             <p style=\"margin-bottom: 10px; font-size: 94%\">\n",
    "#                 LinkedIn <a href=\"https://www.linkedin.com/company/audrey-ai/about/\">Audrey.ai</a>\n",
    "#             </p>\n",
    "#         </div>\"\"\")\n",
    " \n",
    "#     chatbot = gr.Chatbot()\n",
    "#     msg = gr.Textbox(label='User input')\n",
    "#     samples = [[\"이번 주에 친구들과 모임이 있는데, 훌륭한 와인 한 병을 추천해줄래?\"], [\"입문자에게 좋은 와인을 추천해줄래?\"], [\"보르도와 부르고뉴 와인의 차이점은 뭐야?\"]]\n",
    "#     user_response_examples = gr.Dataset(samples=samples, components=[msg], type=\"index\")\n",
    "#     stage_history = gr.Textbox(value=\"stage history: \", interactive=False, label='stage history')\n",
    "#     submit_btn = gr.Button(\"전송\")\n",
    "#     clear_btn = gr.ClearButton([msg, chatbot])\n",
    "#     stage_info = gr.Textbox(value=stage_description, interactive=False, label='stage description')\n",
    "\n",
    "    # def agent_run(agent_exec, inp):\n",
    "    #     agent_exec(inp)\n",
    "\n",
    "\n",
    "#     def load_example(example_id):\n",
    "#         return samples[example_id][0]\n",
    "    \n",
    "#     def submit_user_response(user_response, chat_history):\n",
    "#         return \"\", chat_history + [[user_response, None]]\n",
    "\n",
    "#     def answer(user_response, chat_history, stage_history):\n",
    "#         chat_history = chat_history or []\n",
    "#         stage_history = stage_history or \"\"\n",
    "#         pre_conversation_history = \"\"\n",
    "#         for idx, chat in enumerate(chat_history):\n",
    "#             pre_conversation_history += f\"User: {chat[0]} <END_OF_TURN>\\n\"\n",
    "#             pre_conversation_history += f\"이우선: {chat[1]} <END_OF_TURN>\\n\"\n",
    "#         conversation_history = pre_conversation_history + f\"User: {user_response} <END_OF_TURN>\\n\"\n",
    "\n",
    "#         stage_number = stage_analyzer_chain.run({'conversation_history': conversation_history, 'stage_history': stage_history})\n",
    "#         stage_number = stage_number[-1]\n",
    "#         stage_history += stage_number if stage_history == \"stage history: \" else \", \" + stage_number\n",
    "\n",
    "#         global agent_string\n",
    "#         agent_string = \"\"\n",
    "#         t = threading.Thread(target = agent_run, args=(agent_executor, {'input':user_response, 'conversation_history': pre_conversation_history, 'stage_number': stage_number}))\n",
    "#         t.start()\n",
    "\n",
    "#         while(t.is_alive()):\n",
    "#             time.sleep(0.05)\n",
    "#             chat_history[-1][1] = agent_string\n",
    "#             yield \"\", chat_history, stage_history, gr.Dataset.update(samples=samples)\n",
    "\n",
    "#         t.join()\n",
    "\n",
    "#         conversation_history += \"이우선: \" + agent_string + \"\\n\"\n",
    "#         agent_string = agent_string.split('<END_OF_TURN>')[0]\n",
    "        \n",
    "#         user_response_examples = []\n",
    "        \n",
    "#         for user_response_example in user_response_chain.run({'conversation_history': conversation_history}).split('|'):\n",
    "#             user_response_examples.append([user_response_example])\n",
    "#         samples = user_response_examples\n",
    "\n",
    "#         print(chat_history)\n",
    " \n",
    "#         yield \"\", chat_history, stage_history, gr.Dataset.update(samples=samples)\n",
    "\n",
    "#     def clear(*args):\n",
    "#         samples = [[\"이번 주에 친구들과 모임이 있는데, 훌륭한 와인 한 병을 추천해줄래?\"], [\"입문자에게 좋은 와인을 추천해줄래?\"], [\"보르도와 부르고뉴 와인의 차이점은 뭐야?\"]]\n",
    "#         return gr.Dataset.update(samples=samples), \"stage history: \"\n",
    "\n",
    "#     clear_btn.click(fn=clear, inputs=[user_response_examples, stage_history], outputs=[user_response_examples, stage_history])\n",
    "#     user_response_examples.click(load_example, inputs=[user_response_examples], outputs=[msg])      \n",
    "#     submit_btn.click(submit_user_response, [msg, chatbot], [msg, chatbot]).then(answer, [msg, chatbot, stage_history], [msg, chatbot, stage_history, user_response_examples])\n",
    "#     msg.submit(submit_user_response, [msg, chatbot], [msg, chatbot]).then(answer, [msg, chatbot, stage_history], [msg, chatbot, stage_history, user_response_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c76b17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo.queue()\n",
    "# demo.launch()\n",
    "# # demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14e1d1e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gr\u001b[39m.\u001b[39mclose_all()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gr' is not defined"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc70beca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minsu/miniconda/envs/chatwine/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a534275e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://fe7b7b8592d734b4c9.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://fe7b7b8592d734b4c9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 보르\n",
      " 보르도\n",
      " 보르도와\n",
      " 보르도와 부\n",
      " 보르도와 부르\n",
      " 보르도와 부르\n",
      " 보르도와 부르고\n",
      " 보르도와 부르고뉴 와\n",
      " 보르도와 부르고뉴 와인\n",
      " 보르도와 부르고뉴 와인의\n",
      " 보르도와 부르고뉴 와인의 차\n",
      " 보르도와 부르고뉴 와인의 차이\n",
      " 보르도와 부르고뉴 와인의 차이점\n",
      " 보르도와 부르고뉴 와인의 차이점은\n",
      " 보르도와 부르고뉴 와인의 차이점은 지\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다.\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다.\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다.\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다.\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며,\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다.\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다.\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며,\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르도\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르도네이\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르도네이가\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르도네이가 주로\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르도네이가 주로 사용\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르도네이가 주로 사용되\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르도네이가 주로 사용되\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르도네이가 주로 사용되는 와인\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르도네이가 주로 사용되는 와인입니다\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르도네이가 주로 사용되는 와인입니다.\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르도네이가 주로 사용되는 와인입니다.\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르도네이가 주로 사용되는 와인입니다.\n",
      " 보르도와 부르고뉴 와인의 차이점은 지역과 포도 품종입니다. 보르도 와인은 프랑스 보르도 지역에서 생산되며, 레드와 화이트 와인이 주류입니다. 부르고뉴 와인은 프랑스 부르고뉴 지역에서 생산되며, 피노 누아르와 샤르도네이가 주로 사용되는 와인입니다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 레\n",
      " 레\n",
      " 레드 와\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인이 좋으신가\n",
      " 레드 와인이 좋으신가요, 화이\n",
      " 레드 와인이 좋으신가요, 화이트\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가요\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가요?\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가요?\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가요?\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가요?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 레\n",
      " 레\n",
      " 레드 와\n",
      " 레드 와인\n",
      " 레드 와인\n",
      " 레드 와인이 좋으\n",
      " 레드 와인이 좋으신가\n",
      " 레드 와인이 좋으신가\n",
      " 레드 와인이 좋으신가\n",
      " 레드 와인이 좋으신가요,\n",
      " 레드 와인이 좋으신가요, 화이\n",
      " 레드 와인이 좋으신가요, 화이트\n",
      " 레드 와인이 좋으신가요, 화이트 와인\n",
      " 레드 와인이 좋으신가요, 화이트 와인\n",
      " 레드 와인이 좋으신가요, 화이트 와인\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요,\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가요\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가요?\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가요?\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가요?\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가요?\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가요?\n",
      " 레드 와인이 좋으신가요, 화이트 와인이 좋으신가요, 아니면 로제 와인이 좋으신가요?\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks(css='#chatbot .overflow-y-auto{height:750px}') as demo:\n",
    "    unified_chain = UnifiedChain()\n",
    "    with gr.Row():\n",
    "        gr.HTML(\"\"\"<div style=\"text-align: center; max-width: 500px; margin: 0 auto;\">\n",
    "            <div>\n",
    "                <h1>ChatWine</h1>\n",
    "            </div>\n",
    "            <p style=\"margin-bottom: 10px; font-size: 94%\">\n",
    "                LinkedIn <a href=\"https://www.linkedin.com/company/audrey-ai/about/\">Audrey.ai</a>\n",
    "            </p>\n",
    "        </div>\"\"\")\n",
    "    \n",
    "    chatbot = gr.Chatbot()\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=0.85):\n",
    "            msg = gr.Textbox()\n",
    "        with gr.Column(scale=0.15, min_width=0):\n",
    "            submit_btn = gr.Button(\"전송\")\n",
    "\n",
    "    user_response_examples = gr.Dataset(samples=[[\"이번 주에 친구들과 모임이 있는데, 훌륭한 와인 한 병을 추천해줄래?\"], [\"입문자에게 좋은 와인을 추천해줄래?\"], [\"보르도와 부르고뉴 와인의 차이점은 뭐야?\"]], components=[msg], type=\"index\")\n",
    "    clear_btn = gr.ClearButton([msg, chatbot])\n",
    "\n",
    "    dev_mod = True\n",
    "    cur_stage = gr.Textbox(visible=dev_mod, interactive=False, label='current_stage')\n",
    "    stage_hist = gr.Textbox(visible=dev_mod, value=\"stage history: \", interactive=False, label='stage history')\n",
    "    chat_hist = gr.Textbox(visible=dev_mod, interactive=False, label='chatting_history')\n",
    "    response_examples_text = gr.Textbox(visible=dev_mod, interactive=False, value=\"이번 주에 친구들과 모임이 있는데, 훌륭한 와인 한 병을 추천해줄래?|입문자에게 좋은 와인을 추천해줄래?|보르도와 부르고뉴 와인의 차이점은 뭐야?\", label='response_examples')\n",
    "\n",
    "\n",
    "    def load_example(response_text, input_idx):\n",
    "        response_examples = []\n",
    "        for user_response_example in response_text.split('|'):\n",
    "            response_examples.append([user_response_example])\n",
    "        return response_examples[input_idx][0]\n",
    "\n",
    "    def agent_run(agent_exec, inp, sender):\n",
    "        sender[0] = \"\"\n",
    "        agent_exec.run(inp)\n",
    "\n",
    "    def user_chat(user_message, chat_history_list, chat_history):\n",
    "        return (chat_history_list + [[user_message, None]], chat_history + f\"User: {user_message} <END_OF_TURN>\\n\", [])\n",
    "\n",
    "    def bot_stage_pred(chat_history, stage_history):\n",
    "        stage_number = unified_chain.stage_analyzer_chain.run({'conversation_history': chat_history, 'stage_history': stage_history})\n",
    "        stage_number = stage_number[-1]\n",
    "        stage_history += stage_number if stage_history == \"stage history: \" else \", \" + stage_number\n",
    "\n",
    "        return stage_number, stage_history\n",
    "\n",
    "    def bot_chat(user_response, chat_history, chat_history_list, current_stage): # stream output by yielding\n",
    "        unified_agent = UnifiedAgent()\n",
    "        t = threading.Thread(target = agent_run, args=(unified_agent.agent_executor, {'input':user_response, 'conversation_history': chat_history, 'stage_number': current_stage}, unified_agent.sender))\n",
    "        t.start()\n",
    "\n",
    "        while(t.is_alive()):\n",
    "            time.sleep(0.05)\n",
    "            response = unified_agent.sender[0]\n",
    "            chat_history_list[-1][1] = response\n",
    "            yield chat_history_list, chat_history + f\"이우선: {response}\\n\"\n",
    "\n",
    "        t.join()\n",
    "        response = unified_agent.sender[0]\n",
    "        chat_history_list[-1][1] = response\n",
    "        return chat_history_list, chat_history + f\"이우선: {response}\\n\"\n",
    "\n",
    "    def bot_response_pred(chat_history):\n",
    "        response_examples = []\n",
    "        out = unified_chain.user_response_chain.run({'conversation_history': chat_history})\n",
    "        for user_response_example in out.split('|'):\n",
    "            response_examples.append([user_response_example])\n",
    "        return [response_examples, out, \"\"]\n",
    "\n",
    "    msg.submit(\n",
    "        user_chat, [msg, chatbot, chat_hist], [chatbot, chat_hist, user_response_examples], queue=False\n",
    "    ).then(\n",
    "        bot_stage_pred, [chat_hist, stage_hist], [cur_stage, stage_hist], queue=False\n",
    "    ).then(\n",
    "        bot_chat, [msg, chat_hist, chatbot, cur_stage], [chatbot, chat_hist]\n",
    "    ).then(\n",
    "        bot_response_pred, chat_hist, [user_response_examples, response_examples_text, msg]\n",
    "    )\n",
    "\n",
    "    submit_btn.click(\n",
    "        user_chat, [msg, chatbot, chat_hist], [chatbot, chat_hist, user_response_examples], queue=False\n",
    "    ).then(\n",
    "        bot_stage_pred, [chat_hist, stage_hist], [cur_stage, stage_hist], queue=False\n",
    "    ).then(\n",
    "        bot_chat, [msg, chat_hist, chatbot, cur_stage], [chatbot, chat_hist]\n",
    "    ).then(\n",
    "        bot_response_pred, chat_hist, [user_response_examples, response_examples_text, msg]\n",
    "    )\n",
    "    clear_btn.click(lambda: None, None, chatbot, queue=False)\n",
    "    user_response_examples.click(load_example, inputs=[response_examples_text, user_response_examples], outputs=[msg])\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbcbca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
